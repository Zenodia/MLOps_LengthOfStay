{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ndf13=pd.read_csv('merged.csv')\nX= df13[['rcount', 'gender', 'dialysisrenalendstage', 'asthma',\n       'irondef', 'pneum', 'substancedependence', 'psychologicaldisordermajor',\n       'depress', 'psychother', 'fibrosisandother', 'malnutrition', 'hemo',\n       'hematocrit', 'neutrophils', 'sodium', 'glucose', 'bloodureanitro',\n       'creatinine', 'bmi', 'pulse', 'respiration',\n       'secondarydiagnosisnonicd9',  'fid',\n       'Capacity', 'Name', 'daysofweek_admit',\n       'kmeans', 'meanshift', 'dbscan', 'gmm']].values\n\"\"\"\nfrom sklearn.preprocessing import LabelEncoder\nlb=LabelEncoder()\ny =lb.fit_transform(df13['label'])\ny.shape,y[:5]\n\"\"\"\ny=df13['los_numeric'].values\n#df13.to_csv('merged.csv',index=False)\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.externals import joblib\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": "((80000, 31), (20000, 31), (80000,), (20000,))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## fitting multiple machine learning regression models \nimport timeit\nimport pickle\n# save the model to disk\ndef save_pkl(model, name):\n    filename = name\n    pickle.dump(model, open(filename, 'wb'))\n    \ndef test_load_pkl(name,X_test):\n    loaded_model = pickle.load(open(name, 'rb'))\n    result = loaded_model.predict(X_test)\n\n    return result\n\n\nm='None'\ncurrent_score=1000.\n\ndef find_best_model(current_model_name, new_model_name,current_score, new_score):\n    if new_score<current_score:\n        return new_score , new_model_name\n    else:\n        return current_score , current_model_name\n        \nstart = timeit.default_timer()\n\n#### decision trees \nfrom sklearn.tree import DecisionTreeRegressor\nname='DecisionTree_reg'\nfilename='{}_model.pkl'.format(name)\n#run.tag(\"Description\",\"multi Regressor\")\nmodel = DecisionTreeRegressor(criterion='mse', splitter='best',  min_samples_split=10, min_samples_leaf=1,random_state = 0)\nmodel.fit(X_train, y_train)\n\ny_pred=model.predict(X_test)\n\nX_dat[name]=y_pred\nmse=mean_squared_error(y_test, y_pred)\ncurrent_score,m=find_best_model(m,filename,current_score,mse)\nprint('Mean Squared Error for {} is'.format(name),mse)\n#run.log('{} mse'.format(name), mse)\n\n#run.upload_file(name='outputs/'+'{}_model.pkl'.format(name), path_or_stream='./{}_model.pkl'.format(name))\n#check time took to compute\nstop = timeit.default_timer()\n#run.log('{} time'.format(name), stop-start)\nprint('Time to compute {}: '.format(name), stop - start)  \n\n#### Logisitic regression\nstart = timeit.default_timer()\nfrom sklearn.linear_model import LogisticRegression\nname='Logistic_reg'\n#run.tag(\"Description\",\"{} Regressor\".format(name))\nmodel = LogisticRegression(random_state = 0)\nmodel.fit(X_train, y_train)\nfilename='{}_model.pkl'.format(name)\ny_pred=model.predict(X_test)\n#y_pred = model.predict(X_test)\nX_dat[name]=y_pred\nmse=mean_squared_error(y_test, y_pred)\ncurrent_score,m=find_best_model(m,filename,current_score,mse)\nprint('Mean Squared Error for {} is'.format(name),mse)\n#run.log('{} mse'.format(name), mse)\n#run.upload_file(name='outputs/'+'{}_model.pkl'.format(name), path_or_stream='./{}_model.pkl'.format(name))\n#check time took to compute\nstop = timeit.default_timer()\n#run.log('{} time'.format(name), stop-start)\nprint('Time to compute {}: '.format(name), stop - start)  \n\n#### RandomForest regressor\nstart = timeit.default_timer()\nfrom sklearn.ensemble import RandomForestRegressor\nname='RandomForest_reg'\n#run.tag(\"Description\",\"{} Regressor\".format(name))\nmodel = RandomForestRegressor(n_estimators = 3, random_state = 0) # n_estimator is the # of trees built\nmodel.fit(X_train, y_train)\nfilename='{}_model.pkl'.format(name)\n\ny_pred=model.predict(X_test)\n#y_pred = model.predict(X_test)\nX_dat[name]=y_pred\nmse=mean_squared_error(y_test, y_pred)\ncurrent_score,m=find_best_model(m,filename,current_score,mse)\nprint('Mean Squared Error for {} is'.format(name),mse)\n#run.log('{} mse'.format(name), mse)\n\n#run.upload_file(name='outputs/'+'{}_model.pkl'.format(name), path_or_stream='./{}_model.pkl'.format(name))\n#check time took to compute\nstop = timeit.default_timer()\n#run.log('{} time'.format(name), stop-start)\nprint('Time to compute {}: '.format(name), stop - start)  \n\n#### Support Vector Regressor\n\"\"\"\nstart = timeit.default_timer()\nfrom sklearn.svm import SVR\n#SVR need X to be transformed first so run through the StandardScaler first\nmodel = SVR(kernel = 'rbf') # there are many kernals such as sigmoid, precomputed, poly, linear...etc\nmodel.fit(X_train, y_train)\ny_pred=model.predict(X_test)\nX_dat['svr_pred']=y_pred\nstop = timeit.default_timer()\nprint('Time to compute Support Vector Machine Regressor: ', stop - start)  \n\"\"\"\n### Poly regression\n# Fitting Linear Regression to the dataset\nfrom sklearn.linear_model import LinearRegression\n\n# Fitting Polynomial Regression to the dataset\nstart = timeit.default_timer()\nfrom sklearn.preprocessing import PolynomialFeatures\nname='Poly_reg'\n#run.tag(\"Description\",\"{} Regressor\".format(name))\npoly_reg = PolynomialFeatures(degree = 2)\nX_poly = poly_reg.fit_transform(X_train) # we need to both fit and transform variable X\npoly_reg.fit(X_poly, y_train)\ny_pred=poly_reg.fit_transform(X_test)\n\nlin_reg_2 = LinearRegression()\nlin_reg_2.fit(X_poly, y_train)\ny_pred=lin_reg_2.predict(poly_reg.fit_transform(X_test))\nX_dat[name]=y_pred\nmse=mean_squared_error(y_test, y_pred)\nprint('Mean Squared Error for {} is'.format(name),mse)\n#run.log('{} mse'.format(name), mse)\n\n#run.upload_file(name='outputs/'+'{}_model.pkl'.format(name), path_or_stream='./{}_model.pkl'.format(name))\n#check time took to compute\nstop = timeit.default_timer()\n#run.log('{} time'.format(name), stop-start)\nprint('Time to compute {}: '.format(name), stop - start)  \n\n\n#### rigit regressor\nfrom sklearn.linear_model import Ridge\nname='Ridge_reg'\n#run.tag(\"Description\",\"{} Regressor\".format(name))\nstart = timeit.default_timer()\nreg = Ridge(alpha = 0.03)\nreg.fit(X_train,y_train)\nfilename='{}_model.pkl'.format(name)\ny_pred=model.predict(X_test)\n#y_pred = reg.predict(X_test)\nmse=mean_squared_error(y_test, y_pred)\ncurrent_score,m=find_best_model(m,filename,current_score,mse)\nprint('Mean Squared Error for {} is'.format(name),mse)\n#run.log('{} mse'.format(name), mse)\n#run.upload_file(name='outputs/'+'{}_model.pkl'.format(name), path_or_stream='./{}_model.pkl'.format(name))\n#check time took to compute\nstop = timeit.default_timer()\n#run.log('{} time'.format(name), stop-start)\nprint('Time to compute {}: '.format(name), stop - start)  \nprint(\"best model is \" , m)\n\n#run.complete()\n\n",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Mean Squared Error for DecisionTree_reg is 0.7061799049587427\nTime to compute DecisionTree_reg:  2.153192100000524\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Mean Squared Error for Logistic_reg is 4.1177\nTime to compute Logistic_reg:  32.15974670000014\nMean Squared Error for RandomForest_reg is 0.5551666666666666\nTime to compute RandomForest_reg:  4.59471510000003\nMean Squared Error for Poly_reg is 0.7043000408770214\nTime to compute Poly_reg:  80.5362710999998\nMean Squared Error for Ridge_reg is 0.5551666666666666\nTime to compute Ridge_reg:  0.23420090000035998\nbest model is  RandomForest_reg_model.pkl\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>rcount</th>\n      <th>gender</th>\n      <th>dialysisrenalendstage</th>\n      <th>asthma</th>\n      <th>irondef</th>\n      <th>pneum</th>\n      <th>substancedependence</th>\n      <th>psychologicaldisordermajor</th>\n      <th>depress</th>\n      <th>psychother</th>\n      <th>...</th>\n      <th>kmeans</th>\n      <th>meanshift</th>\n      <th>dbscan</th>\n      <th>gmm</th>\n      <th>label</th>\n      <th>DecisionTree_reg</th>\n      <th>Logistic_reg</th>\n      <th>RandomForest_reg</th>\n      <th>Poly_reg</th>\n      <th>Ridge_reg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3582</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.194934</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>60498</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>3.000000</td>\n      <td>3.0</td>\n      <td>3.000000</td>\n      <td>3.749017</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>53227</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>4.571429</td>\n      <td>2.0</td>\n      <td>4.333333</td>\n      <td>3.911644</td>\n      <td>4.333333</td>\n    </tr>\n    <tr>\n      <th>21333</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>7.0</td>\n      <td>1.000000</td>\n      <td>1.383664</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3885</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.306935</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 37 columns</p>\n</div>",
            "text/plain": "      rcount gender dialysisrenalendstage asthma irondef pneum  \\\n3582     NaN    NaN                   NaN    NaN     NaN   NaN   \n60498    NaN    NaN                   NaN    NaN     NaN   NaN   \n53227    NaN    NaN                   NaN    NaN     NaN   NaN   \n21333    NaN    NaN                   NaN    NaN     NaN   NaN   \n3885     NaN    NaN                   NaN    NaN     NaN   NaN   \n\n      substancedependence psychologicaldisordermajor depress psychother  \\\n3582                  NaN                        NaN     NaN        NaN   \n60498                 NaN                        NaN     NaN        NaN   \n53227                 NaN                        NaN     NaN        NaN   \n21333                 NaN                        NaN     NaN        NaN   \n3885                  NaN                        NaN     NaN        NaN   \n\n         ...    kmeans meanshift dbscan gmm label DecisionTree_reg  \\\n3582     ...       NaN       NaN    NaN NaN   1.0         1.000000   \n60498    ...       NaN       NaN    NaN NaN   3.0         3.000000   \n53227    ...       NaN       NaN    NaN NaN   4.0         4.571429   \n21333    ...       NaN       NaN    NaN NaN   1.0         1.000000   \n3885     ...       NaN       NaN    NaN NaN   1.0         1.000000   \n\n      Logistic_reg RandomForest_reg  Poly_reg Ridge_reg  \n3582           1.0         1.000000  1.194934  1.000000  \n60498          3.0         3.000000  3.749017  3.000000  \n53227          2.0         4.333333  3.911644  4.333333  \n21333          7.0         1.000000  1.383664  1.000000  \n3885           1.0         1.000000  1.306935  1.000000  \n\n[5 rows x 37 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\"\"\"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# setting the static parameters\nrfr = RandomForestRegressor(bootstrap=True, random_state=0, n_jobs=2)\n\nparam_grid = dict(n_estimators=[ 57,129,223],\n                  max_depth=[10, 25 ,50],\n                  min_samples_leaf=[10,100,250])\n\ngrid = GridSearchCV(rfr, param_grid, cv=10,\n                    scoring='neg_mean_squared_error')\ngrid.fit(X_train,y_train)\n\nprint(\"Grid scores on development set:\\n\")\nfor params, mean_score, scores in grid.grid_scores_:\n    print (\"%0.3f (+/-%0.03f) for %r\\n\" % (mean_score, scores.std() * 2, params))\n\nprint(\"MSE for test data set:\\n\")\ny_true, y_pred = y_test, grid.predict(X_test)\nprint(mean_squared_error(y_true, y_pred) )\n\"\"\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nstart = timeit.default_timer()\nfrom sklearn.ensemble import RandomForestRegressor\nname='RandomForest_reg'\n#run.tag(\"Description\",\"{} Regressor\".format(name))\nmodel = RandomForestRegressor(n_estimators = 57 ,random_state = 0) # n_estimator is the # of trees built\nmodel.fit(X_train, y_train)\nfilename='LOS_RF_model.pkl'.format(name)\nsave_pkl(model,filename)\ny_pred= test_load_pkl(filename,X_test)\nmse=mean_squared_error(y_test, y_pred)\nprint('Mean Squared Error for {} is'.format(name),mse)\n",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Mean Squared Error for RandomForest_reg is 0.3854665589412127\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## deploy to ACI \n# Check core SDK version number\nimport azureml.core\n\nprint(\"SDK version:\", azureml.core.VERSION)",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": "SDK version: 1.0.33\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace\n\nws = Workspace.from_config()\nprint(ws.name, ws.resource_group, ws.location, sep = '\\n')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.model import Model\nimport sklearn\n\nlibrary_version = \"sklearn\"+sklearn.__version__.replace(\".\",\"x\")\n\nmodel = Model.register(model_path = \"LOS_RF_model.pkl\",\n                       model_name = \"LOS_RF_model.pkl\",\n                       tags = {'area': \"LengthOfStay\", 'type': \"regression\", 'version': library_version},\n                       description = \"RF regression model to predict LengthOfStay\",\n                       workspace = ws)",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Registering model LOS_RF_model.pkl\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "regression_models = Model.list(workspace=ws, tags=['area'])\nfor m in regression_models:\n    print(\"Name:\", m.name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)\n\nprint(model.name, model.description, model.version, sep = '\\t')",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Name: LOS_RF_model.pkl \tVersion: 2 \tDescription: RF regression model to predict LengthOfStay {'area': 'LengthOfStay', 'type': 'regression', 'version': 'sklearn0x20x3'}\nName: LOS_RF_model.pkl \tVersion: 1 \tDescription: RF regression model to predict LengthOfStay {'area': 'LengthOfStay', 'type': 'regression', 'version': 'sklearn0x20x3'}\nName: RF_model.pkl \tVersion: 2 \tDescription: Randomforest model to predict breastcancer {'area': 'breastcancer', 'type': 'classification'}\nName: model.pkl \tVersion: 2 \tDescription: Sample anomaly detection model for IOT tutorial {'area': 'anomaly', 'type': 'classification'}\nName: model.pkl \tVersion: 1 \tDescription: Sample anomaly detection model for IOT tutorial {'area': 'anomaly', 'type': 'classification'}\nName: CNN_spiral_parkinson.h5 \tVersion: 2 \tDescription: image classification to predict parkinson {'area': 'elderly_disease', 'type': 'classification'}\nName: CNN_spiral_parkinson.h5 \tVersion: 1 \tDescription: image classification to predict parkinson {'area': 'elderly_disease', 'type': 'classification'}\nName: FC_spiral_parkinson.h5 \tVersion: 1 \tDescription: image classification to predict parkinson {'area': 'elderly_disease', 'type': 'classification'}\nLOS_RF_model.pkl\tRF regression model to predict LengthOfStay\t2\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile score.py\nimport pickle\nimport json\nimport numpy\nfrom sklearn.linear_model import Ridge\nfrom azureml.core.model import Model\n\ndef init():\n    global model\n    # note here \"sklearn_regression_model.pkl\" is the name of the model registered under\n    # this is a different behavior than before when the code is run locally, even though the code is the same.\n    model_path = Model.get_model_path('LOS_RF_model.pkl')\n    # deserialize the model file back into a sklearn model\n    model = pickle.load(open(model_path, 'rb'))\n\n# note you can pass in multiple rows for scoring\ndef run(raw_data):\n    try:\n        data = json.loads(raw_data)['data']\n        data = numpy.array(data)\n        result = model.predict(data)\n        # you can return any datatype as long as it is JSON-serializable\n        return result.tolist()\n    except Exception as e:\n        error = str(e)\n        return error",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting score.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nfrom azureml.core.conda_dependencies import CondaDependencies \n\nmyenv = CondaDependencies.create(conda_packages=['numpy','scikit-learn'])\n\nwith open(\"myenv.yml\",\"w\") as f:\n    f.write(myenv.serialize_to_string())",
      "execution_count": 53,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.image import Image, ContainerImage\n\nimage_config = ContainerImage.image_configuration(runtime= \"python\",\n                                 execution_script=\"score.py\",\n                                 conda_file=\"myenv.yml\",\n                                 tags = {'area': \"los\", 'type': \"regression\"},\n                                 description = \"Image with randomforest regression model\")\n\nimage = Image.create(name = \"los-image3\",\n                     # this is the model object. note you can pass in 0-n models via this list-type parameter\n                     # in case you need to reference multiple models, or none at all, in your scoring script.\n                     models = [model],\n                     image_config = image_config, \n                     workspace = ws)",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Creating image\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "image.wait_for_creation(show_output = True)",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Running.......................................................\nSucceededImage creation operation finished for image los-image3:1, operation \"Succeeded\"\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for i in Image.list(workspace = ws,tags = [\"area\"]):\n    print('{}(v.{} [{}]) stored at {} with build log {}'.format(i.name, i.version, i.creation_state, i.image_location, i.image_build_log_uri))",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": "los-image3(v.1 [Succeeded]) stored at wsaml7468722711.azurecr.io/los-image3:1 with build log https://wsaml5463730571.blob.core.windows.net/azureml/ImageLogs/a10ffba4-20b6-4cfd-bae4-bf4b63109223/build.log?sv=2018-03-28&sr=b&sig=dkEzwPW1gxhPZEEnFWFqG9TdhCoup64D%2B1x6pK8eWxk%3D&st=2019-06-05T13%3A49%3A42Z&se=2019-07-05T13%3A54%3A42Z&sp=rl\nlos-image2(v.1 [Succeeded]) stored at wsaml7468722711.azurecr.io/los-image2:1 with build log https://wsaml5463730571.blob.core.windows.net/azureml/ImageLogs/fce1b8c6-e542-4de4-9f98-e701eefd98d9/build.log?sv=2018-03-28&sr=b&sig=Y4Jlrr1hVUQdZnUwxASnLgbZA6hlql1%2B%2B3rMEcTv1CY%3D&st=2019-06-05T13%3A49%3A42Z&se=2019-07-05T13%3A54%3A42Z&sp=rl\nlos-image1(v.1 [Succeeded]) stored at wsaml7468722711.azurecr.io/los-image1:1 with build log https://wsaml5463730571.blob.core.windows.net/azureml/ImageLogs/62793e81-8468-4cc4-87a7-1f02f3fd915c/build.log?sv=2018-03-28&sr=b&sig=5uxuaVpaG11OoS86qc84%2FGjFQ34sji%2FiVtkfxwsdrWU%3D&st=2019-06-05T13%3A49%3A42Z&se=2019-07-05T13%3A54%3A42Z&sp=rl\nmyimage2(v.1 [Failed]) stored at wsaml7468722711.azurecr.io/myimage2:1 with build log https://wsaml5463730571.blob.core.windows.net/azureml/ImageLogs/b65e5ff9-8e73-48f8-99e0-1a827bc4d34f/build.log?sv=2018-03-28&sr=b&sig=4eJIUI9ErjSoLF6vhvmm5zGI5KGJwapJypz7iq7krmI%3D&st=2019-06-05T13%3A49%3A42Z&se=2019-07-05T13%3A54%3A42Z&sp=rl\ntempanomalydetection(v.2 [Succeeded]) stored at wsaml7468722711.azurecr.io/tempanomalydetection:2 with build log https://wsaml5463730571.blob.core.windows.net/azureml/ImageLogs/211ad3da-2fbd-4028-aeee-e5d247df19b4/build.log?sv=2018-03-28&sr=b&sig=jhTYHEfpIw9DHm9oeJa%2B3TgZe0AQbbVTl%2BvzGRJi5qo%3D&st=2019-06-05T13%3A49%3A43Z&se=2019-07-05T13%3A54%3A43Z&sp=rl\ntempanomalydetection(v.1 [Succeeded]) stored at wsaml7468722711.azurecr.io/tempanomalydetection:1 with build log https://wsaml5463730571.blob.core.windows.net/azureml/ImageLogs/af0e9216-ce95-422a-87b1-0de00773a937/build.log?sv=2018-03-28&sr=b&sig=YrBvpGwTNVOl9QL4QSgwCfAZtJpe8GKhh2tdBIlMP%2BU%3D&st=2019-06-05T13%3A49%3A43Z&se=2019-07-05T13%3A54%3A43Z&sp=rl\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nfrom azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n                                               memory_gb = 1, \n                                               tags = {'area': \"los\", 'type': \"regression\"}, \n                                               description = 'Predict los using regression model')",
      "execution_count": 57,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nfrom azureml.core.webservice import Webservice\n\naci_service_name = 'los-aci-service-1'\nprint(aci_service_name)\naci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n                                           image = image,\n                                           name = aci_service_name,\n                                           workspace = ws)\naci_service.wait_for_deployment(True)\nprint(aci_service.state)",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": "los-aci-service-1\nCreating service\nRunning......................\nSucceededACI service creation operation finished, operation \"Succeeded\"\nHealthy\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "aci_service.get_logs()",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 59,
          "data": {
            "text/plain": "\"2019-06-05T13:56:38,094276427+00:00 - iot-server/run \\n2019-06-05T13:56:38,093763224+00:00 - rsyslog/run \\n2019-06-05T13:56:38,101455373+00:00 - gunicorn/run \\n2019-06-05T13:56:38,113264748+00:00 - nginx/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2019-06-05T13:56:38,370109876+00:00 - iot-server/finish 1 0\\n2019-06-05T13:56:38,371319183+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.6.0\\nListening at: http://127.0.0.1:9090 (18)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 48\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user's init function\\n2019-06-05 13:56:42,025 | azureml.core.run | DEBUG | Could not load run context Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run., switching offline: False\\n2019-06-05 13:56:42,025 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\\n2019-06-05 13:56:42,025 | azureml.core.model | DEBUG | RunEnvironmentException: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\\n2019-06-05 13:56:42,025 | azureml.core.model | DEBUG | version is None. Latest version is 2\\n2019-06-05 13:56:42,025 | azureml.core.model | DEBUG | Found model path at azureml-models/LOS_RF_model.pkl/2/LOS_RF_model.pkl\\n/opt/miniconda/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.20.3 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\\n  UserWarning)\\n/opt/miniconda/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.20.3 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\\n  UserWarning)\\nUsers's init has completed successfully\\nScoring timeout setting is not found. Use default timeout: 3600000 ms\\n\""
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "aci_service.scoring_uri",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 63,
          "data": {
            "text/plain": "'http://2bf5e848-1a86-4dcc-b13a-9c818ea0b492.westeurope.azurecontainer.io/score'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nimport json\n\ntest_sample = json.dumps({'data': [\nX_test[0].tolist()\n]})\ntest_sample = bytes(test_sample,encoding = 'utf8')\n\nprediction = aci_service.run(input_data=test_sample)\nprint(prediction)",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[1.0]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "aci_service.delete()",
      "execution_count": 67,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}